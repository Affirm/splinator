{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e78896aa-cc54-43ec-9383-305384cdf0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be2926e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a340130b-0102-44f0-a6b9-0dfbe3662025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinator.estimators import LinearSplineLogisticRegression, CDFSplineCalibrator\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss, log_loss\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import (NeighborhoodComponentsAnalysis, KNeighborsClassifier)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from splinator.metrics import expected_calibration_error, spiegelhalters_z_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b82661c-7b25-4222-ba79-11e1f948167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant imports - already imported above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a034bd3d-3a2a-4dd5-a9c0-f95c761d7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant import - already imported above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b144f0-73c1-4c54-8e02-5468a7a294dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=50000, n_features=10, n_informative=2, n_redundant=8, flip_y=0.15)\n",
    "\n",
    "# split train, test for calibration\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b552efac-8fbd-45c5-ad13-86e4d4c618d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf_pred_dev = clf.predict_proba(X_dev)[:,1]\n",
    "clf_pred_test = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b8c065e-8890-4e58-a4cf-4b9c204e4a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.893854084279575"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_score=clf_pred_dev, y_true=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "983f189a-a9ba-4348-8bb9-193db84e3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LinearSplineLogisticRegression...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearSplineLogisticRegression' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m lslr \u001b[38;5;241m=\u001b[39m LinearSplineLogisticRegression(\n\u001b[1;32m      4\u001b[0m         n_knots\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, \n\u001b[1;32m      5\u001b[0m         monotonicity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m         two_stage_fitting_initial_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m lslr\u001b[38;5;241m.\u001b[39mfit(clf_pred_dev\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), y_dev)\n\u001b[0;32m---> 11\u001b[0m lslr_pred \u001b[38;5;241m=\u001b[39m \u001b[43mlslr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m(clf_pred_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting KSSplineCalibrator...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m ks_cal \u001b[38;5;241m=\u001b[39m KSSplineCalibrator(n_knots\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearSplineLogisticRegression' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "# Fit all spline-based calibrators\n",
    "print(\"Fitting LinearSplineLogisticRegression...\")\n",
    "lslr = LinearSplineLogisticRegression(\n",
    "        n_knots=20, \n",
    "        monotonicity=\"none\", \n",
    "        minimizer_options={'disp': False}, \n",
    "        method='SLSQP', \n",
    "        two_stage_fitting_initial_size=2000\n",
    "    )\n",
    "lslr.fit(clf_pred_dev.reshape(-1, 1), y_dev)\n",
    "lslr_pred = lslr.predict_proba(clf_pred_test.reshape(-1, 1))[:, 1]\n",
    "\n",
    "print(\"Fitting CDFSplineCalibrator...\")\n",
    "cdf_cal = CDFSplineCalibrator(num_knots=6)\n",
    "cdf_cal.fit(clf_pred_dev.reshape(-1, 1), y_dev)\n",
    "cdf_pred = cdf_cal.predict_proba(clf_pred_test.reshape(-1, 1))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e623a437-ea10-47f1-b9ec-e68ad29663f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting PyGAM...\")\n",
    "from pygam import GAM, s, te\n",
    "\n",
    "gam_model = GAM(s(0, n_splines=20, spline_order=1), distribution='binomial', link='logit', fit_intercept=True)\n",
    "gam_model.fit(clf_pred_dev.reshape(-1, 1), y_dev)\n",
    "gam_model_pred = gam_model.predict_proba(clf_pred_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7647e9cc-3f8d-4369-be53-1f4c0699ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already imported at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903fd313-8c25-435e-b3ce-9a2c7c4f07e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "df = pd.DataFrame({\n",
    "    'uncalibrated': clf_pred_test,\n",
    "    'y_true': y_test,\n",
    "    'lslr': lslr_pred,\n",
    "    'cdf_spline': cdf_pred,\n",
    "    'pygam': gam_model_pred,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a1f150-7a08-49e7-aa1e-d70ea4241c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for all methods\n",
    "methods = ['uncalibrated', 'lslr', 'cdf_spline', 'pygam']\n",
    "results = []\n",
    "\n",
    "for method in methods:\n",
    "    brier = brier_score_loss(y_test, df[method])\n",
    "    logloss = log_loss(y_test, df[method])\n",
    "    ece = expected_calibration_error(y_test, df[method])\n",
    "    z_stat = spiegelhalters_z_statistic(y_test, df[method])\n",
    "    \n",
    "    results.append({\n",
    "        'Method': method,\n",
    "        'Brier Score': brier,\n",
    "        'Log Loss': logloss,\n",
    "        'ECE': ece,\n",
    "        'Spiegelhalter Z': z_stat\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b261a896-7445-4b63-81e5-6cd6594da4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot calibration curves for all methods\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Sample data for cleaner visualization\n",
    "sample_size = 1000\n",
    "sample_idx = np.random.choice(len(df), sample_size, replace=False)\n",
    "sample_df = df.iloc[sample_idx].sort_values('uncalibrated')\n",
    "\n",
    "# Plot each method\n",
    "plt.plot(sample_df['uncalibrated'], sample_df['lslr'], \n",
    "         label='LinearSplineLogisticRegression', linewidth=2, alpha=0.8)\n",
    "plt.plot(sample_df['uncalibrated'], sample_df['cdf_spline'], \n",
    "         label='CDFSplineCalibrator', linewidth=2, alpha=0.8)\n",
    "plt.plot(sample_df['uncalibrated'], sample_df['pygam'], \n",
    "         label='PyGAM', linewidth=2, alpha=0.8)\n",
    "\n",
    "# Add diagonal reference line\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Perfect calibration', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Uncalibrated Probability', fontsize=12)\n",
    "plt.ylabel('Calibrated Probability', fontsize=12)\n",
    "plt.title('Calibration Curves Comparison', fontsize=14)\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b67e634-c3ab-4bf9-a959-4a6cbdfed88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f596414-3296-4b78-8cbb-778a12dd0858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the spline transformations more closely\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Sort by uncalibrated scores for better visualization\n",
    "sorted_idx = np.argsort(clf_pred_test)\n",
    "x_sorted = clf_pred_test[sorted_idx]\n",
    "\n",
    "# Plot each spline method's transformation\n",
    "spline_methods = [\n",
    "    (lslr_pred[sorted_idx], 'LinearSplineLogisticRegression', axes[0]),\n",
    "    (cdf_pred[sorted_idx], 'CDFSplineCalibrator', axes[1]),\n",
    "    (gam_model_pred[sorted_idx], 'PyGAM', axes[2])\n",
    "]\n",
    "\n",
    "for pred, title, ax in spline_methods:\n",
    "    # Plot transformation\n",
    "    ax.plot(x_sorted, pred, linewidth=2, label='Calibrated', color='blue')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='No change')\n",
    "    \n",
    "    # Highlight regions where calibration changes most\n",
    "    diff = np.abs(pred - x_sorted)\n",
    "    ax.fill_between(x_sorted, x_sorted, pred, where=(diff > 0.05), \n",
    "                    alpha=0.3, color='red', label='Large adjustment (>0.05)')\n",
    "    \n",
    "    ax.set_xlabel('Uncalibrated Probability', fontsize=11)\n",
    "    ax.set_ylabel('Calibrated Probability', fontsize=11)\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.legend(loc='best', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c6a69-0735-476c-af67-df945699a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary comparison plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Normalize metrics for better visualization\n",
    "metrics_normalized = results_df.copy()\n",
    "metrics_normalized['Brier Score'] = 1 - metrics_normalized['Brier Score'] / metrics_normalized.loc[0, 'Brier Score']\n",
    "metrics_normalized['Log Loss'] = 1 - metrics_normalized['Log Loss'] / metrics_normalized.loc[0, 'Log Loss']\n",
    "metrics_normalized['ECE'] = 1 - metrics_normalized['ECE'] / metrics_normalized.loc[0, 'ECE']\n",
    "metrics_normalized['Spiegelhalter Z'] = 1 - np.abs(metrics_normalized['Spiegelhalter Z']) / np.abs(metrics_normalized.loc[0, 'Spiegelhalter Z'])\n",
    "\n",
    "# Plot bars\n",
    "x = np.arange(len(methods))\n",
    "width = 0.2\n",
    "\n",
    "metrics_to_plot = ['Brier Score', 'Log Loss', 'ECE', 'Spiegelhalter Z']\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    offset = (i - 1.5) * width\n",
    "    ax.bar(x + offset, metrics_normalized[metric], width, \n",
    "           label=f'{metric} improvement', color=colors[i], alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Method', fontsize=12)\n",
    "ax.set_ylabel('Relative Improvement (higher is better)', fontsize=12)\n",
    "ax.set_title('Calibration Performance Comparison', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(methods, rotation=45, ha='right')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print percentage improvements\n",
    "print(\"\\nPercentage improvements over uncalibrated:\")\n",
    "for i in range(1, len(results_df)):\n",
    "    print(f\"\\n{results_df.loc[i, 'Method']}:\")\n",
    "    print(f\"  Brier Score: {(1 - results_df.loc[i, 'Brier Score']/results_df.loc[0, 'Brier Score']) * 100:.1f}%\")\n",
    "    print(f\"  Log Loss: {(1 - results_df.loc[i, 'Log Loss']/results_df.loc[0, 'Log Loss']) * 100:.1f}%\")\n",
    "    print(f\"  ECE: {(1 - results_df.loc[i, 'ECE']/results_df.loc[0, 'ECE']) * 100:.1f}%\")\n",
    "    print(f\"  |Spiegelhalter Z|: {(1 - abs(results_df.loc[i, 'Spiegelhalter Z'])/abs(results_df.loc[0, 'Spiegelhalter Z'])) * 100:.1f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
